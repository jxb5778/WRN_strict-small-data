{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_cnn_baseline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K71UCSTBlI5m"
      },
      "source": [
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "!pip install keras_wrn\n",
        "import keras_wrn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puRWjFSD6v8Y"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uefmwSGUliZM"
      },
      "source": [
        "# Construct a tf.data.Dataset\n",
        "train_images, train_info = tfds.load(\n",
        "    'cifar100', \n",
        "    split='train[:80%]', \n",
        "    shuffle_files=True, \n",
        "    with_info=True, \n",
        "    as_supervised=True)\n",
        "\n",
        "dev_images, dev_info = tfds.load(\n",
        "    'cifar100', \n",
        "    split='train[-20%:]', \n",
        "    shuffle_files=True, \n",
        "    with_info=True, \n",
        "    as_supervised=True)\n",
        "\n",
        "test_images, test_info = tfds.load(\n",
        "    'cifar100', \n",
        "    split='test', \n",
        "    shuffle_files=True, \n",
        "    with_info=True, \n",
        "    as_supervised=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eey1xeimWPz"
      },
      "source": [
        "\n",
        "fig = tfds.show_examples(dev_images, dev_info)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZOyidx1oxoI"
      },
      "source": [
        "input_shape = train_info.features[\"image\"].shape\n",
        "num_classes = train_info.features[\"label\"].num_classes \n",
        "print(\"Image shape: \", input_shape)\n",
        "print(\"Labels:\\n\", train_info.features[\"label\"].names)\n",
        "print(\"Number of Labels: \", num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baNXj6UVrEDh"
      },
      "source": [
        "def normalize_image(image, label):\n",
        "\n",
        "  norm_image = tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "  return norm_image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Nt5OjdrD3x"
      },
      "source": [
        "\n",
        "batch_size = 100\n",
        "\n",
        "train_images = train_images.map(normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "train_images = train_images.cache()\n",
        "train_images = train_images.shuffle(train_info.splits['train'].num_examples).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "dev_images = dev_images.map(normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(batch_size)\n",
        "dev_images = dev_images.cache()\n",
        "dev_images = dev_images.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "test_images = test_images.map(normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(batch_size)\n",
        "test_images = test_images.cache()\n",
        "test_images = test_images.prefetch(tf.data.experimental.AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlCjRj7ustWI"
      },
      "source": [
        "\n",
        "model = keras_wrn.build_model(\n",
        "    input_dims=input_shape, \n",
        "    output_dim=num_classes,\n",
        "    n=40,\n",
        "    k=2\n",
        "    )\n",
        "\n",
        "\"\"\"\n",
        "model = tf.keras.Sequential([\n",
        "                             \n",
        "      tf.keras.layers.Conv2D(32, 5, strides=1, padding='same', activation=tf.nn.leaky_relu, input_shape=input_shape),\n",
        "      tf.keras.layers.Conv2D(32, 5, strides=2, padding='same', activation=tf.nn.leaky_relu),\n",
        "      tf.keras.layers.Conv2D(64, 5, strides=1, padding='same', activation=tf.nn.leaky_relu),\n",
        "      tf.keras.layers.Conv2D(64, 5, strides=2, padding='same', activation=tf.nn.leaky_relu),\n",
        "      tf.keras.layers.Conv2D(128, 7, strides=1, padding='valid', activation=tf.nn.leaky_relu),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "      tf.keras.layers.Dropout(0.4),\n",
        "      tf.keras.layers.Dense(100, activation=\"softmax\"),                   \n",
        "])\n",
        "\"\"\"\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F5ASGAesv8R"
      },
      "source": [
        "model.fit(train_images, validation_data=dev_images, epochs=250)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n1t2GEG3jln"
      },
      "source": [
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_images)\n",
        "\n",
        "print(f'Test Loss: {test_loss}; Test Accuracy: {test_accuracy}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYicKBeKuPqa"
      },
      "source": [
        "pred_labels = model.predict(test_images)\n",
        "pred_labels = np.argmax(pred_labels, axis=1)\n",
        "print(pred_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OLzMONmupla"
      },
      "source": [
        "test_labels = np.array([labels.numpy() for images, labels in test_images])\n",
        "test_labels = np.concatenate(test_labels, axis=None)\n",
        "\n",
        "print(test_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9S6316Mymsa"
      },
      "source": [
        "\n",
        "PROJ_DIR = '/content/drive/My Drive/data/ml'\n",
        "out_file = f'{PROJ_DIR}/cnn_sub10.csv'\n",
        "\n",
        "report = metrics.classification_report(test_labels, pred_labels, output_dict=True)\n",
        "\n",
        "df = pd.DataFrame(report).transpose()\n",
        "\n",
        "df.to_csv(out_file, index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}